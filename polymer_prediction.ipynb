{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8Ucule9o5ckvzBOTi/pIi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NEu1eggha0ut"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets scikit-learn torch --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaModel, RobertaPreTrainedModel, Trainer, TrainingArguments, RobertaConfig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "targets = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")"
      ],
      "metadata": {
        "id": "psVLgkIJep_8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SMILESDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, smiles_list, labels=None, masks=None):\n",
        "        self.encodings = tokenizer(smiles_list, truncation=True, padding='max_length', max_length=128)\n",
        "        self.labels = labels\n",
        "        self.masks = masks\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            labels = np.nan_to_num(self.labels[idx], nan=0.0)\n",
        "            item['labels'] = torch.tensor(labels, dtype=torch.float32)\n",
        "            if self.masks is not None:\n",
        "                item['label_mask'] = torch.tensor(self.masks[idx], dtype=torch.float32)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])"
      ],
      "metadata": {
        "id": "LvJ793dQemdn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChemBERTaRegressor(RobertaPreTrainedModel):\n",
        "    def __init__(self, config, num_targets=5):\n",
        "        super().__init__(config)\n",
        "        self.roberta = RobertaModel(config)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.regressor = nn.Linear(config.hidden_size, num_targets)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "      outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      pooled_output = outputs.pooler_output\n",
        "      pooled_output = self.dropout(pooled_output)\n",
        "      logits = self.regressor(pooled_output)\n",
        "\n",
        "      if labels is not None:\n",
        "          if logits.shape != labels.shape:\n",
        "              raise ValueError(f\"Shape mismatch: logits {logits.shape}, labels {labels.shape}\")\n",
        "          if torch.isnan(logits).any():\n",
        "              print(\"Warning: NaN detected in predictions\")\n",
        "          if torch.isnan(labels).any():\n",
        "              print(\"Warning: NaN detected in labels\")\n",
        "\n",
        "          loss = self.loss_fn(logits, labels)\n",
        "          return {\"loss\": loss, \"logits\": logits}\n",
        "      else:\n",
        "          return {\"logits\": logits}"
      ],
      "metadata": {
        "id": "FmH0PNm2iRfM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTrainer(Trainer):\n",
        "    def training_step(self, model, inputs):\n",
        "        model.train()\n",
        "        inputs = self._prepare_inputs(inputs)\n",
        "\n",
        "        loss = self.compute_loss(model, inputs)\n",
        "\n",
        "        if self.args.gradient_accumulation_steps > 1:\n",
        "            loss = loss / self.args.gradient_accumulation_steps\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        return loss.detach()"
      ],
      "metadata": {
        "id": "kWkSv8ET9xZF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df['SMILES'].tolist()\n",
        "y = train_df[targets].values\n",
        "\n",
        "valid_mask = ~np.isnan(y)\n",
        "y_for_scaling = np.nan_to_num(y, nan=0.0)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "y_scaled = np.zeros_like(y_for_scaling)\n",
        "\n",
        "for i, target in enumerate(targets):\n",
        "    valid_indices = valid_mask[:, i]\n",
        "    if valid_indices.sum() > 1:\n",
        "        target_values = y[valid_indices, i:i+1]\n",
        "        scaler_target = StandardScaler()\n",
        "        scaler_target.fit(target_values)\n",
        "\n",
        "        y_scaled[:, i] = scaler_target.transform(y_for_scaling[:, i:i+1]).flatten()\n",
        "\n",
        "        if not hasattr(scaler, 'target_scalers'):\n",
        "            scaler.target_scalers = {}\n",
        "        scaler.target_scalers[i] = scaler_target\n",
        "    else:\n",
        "        print(f\"Warning: Not enough valid values for target {target}\")\n",
        "        y_scaled[:, i] = y_for_scaling[:, i]\n",
        "\n",
        "for i, target in enumerate(targets):\n",
        "    valid_indices = valid_mask[:, i]\n",
        "    if valid_indices.sum() > 0:\n",
        "        orig_mean = np.nanmean(y[:, i])\n",
        "        orig_std = np.nanstd(y[:, i])\n",
        "        scaled_mean = np.mean(y_scaled[valid_indices, i])\n",
        "        scaled_std = np.std(y_scaled[valid_indices, i])\n",
        "        print(f\"{target}: orig_mean={orig_mean:.3f}, orig_std={orig_std:.3f} -> scaled_mean={scaled_mean:.3f}, scaled_std={scaled_std:.3f}\")\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "test_dataset = SMILESDataset(test_df['SMILES'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=8)"
      ],
      "metadata": {
        "id": "sAIiD8JyiZ4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2487fa8-d876-4abf-fcbb-8df1ca806cde"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tg: orig_mean=96.452, orig_std=111.119 -> scaled_mean=0.000, scaled_std=1.000\n",
            "FFV: orig_mean=0.367, orig_std=0.030 -> scaled_mean=0.000, scaled_std=1.000\n",
            "Tc: orig_mean=0.256, orig_std=0.089 -> scaled_mean=0.000, scaled_std=1.000\n",
            "Density: orig_mean=0.985, orig_std=0.146 -> scaled_mean=0.000, scaled_std=1.000\n",
            "Rg: orig_mean=16.420, orig_std=4.605 -> scaled_mean=-0.000, scaled_std=1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "fold_maes = []\n",
        "test_preds_folds = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "    print(f\"--- Fold {fold+1} ---\")\n",
        "\n",
        "    X_train = [X[i] for i in train_idx]\n",
        "    X_val = [X[i] for i in val_idx]\n",
        "    y_train = y_scaled[train_idx]\n",
        "    y_val = y_scaled[val_idx]\n",
        "    mask_train = valid_mask[train_idx]\n",
        "    mask_val = valid_mask[val_idx]\n",
        "\n",
        "    train_dataset = SMILESDataset(X_train, y_train, mask_train)\n",
        "    val_dataset = SMILESDataset(X_val, y_val, mask_val)\n",
        "\n",
        "    config = RobertaConfig.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
        "    model = ChemBERTaRegressor.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\", config=config).to(device)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_fold_{fold}\",\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=50,\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=50,\n",
        "        save_strategy=\"no\",\n",
        "        learning_rate=1e-5,\n",
        "        warmup_steps=100,\n",
        "        weight_decay=0.01,\n",
        "        dataloader_num_workers=0,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        trainer.train()\n",
        "    except Exception as e:\n",
        "        print(f\"Training failed for fold {fold+1}: {e}\")\n",
        "        continue\n",
        "\n",
        "    val_preds_scaled = trainer.predict(val_dataset).predictions\n",
        "\n",
        "    val_preds = np.zeros_like(val_preds_scaled)\n",
        "    y_val_original = np.zeros_like(y_val)\n",
        "\n",
        "    for i, target in enumerate(targets):\n",
        "        if hasattr(scaler, 'target_scalers') and i in scaler.target_scalers:\n",
        "            val_preds[:, i] = scaler.target_scalers[i].inverse_transform(\n",
        "                val_preds_scaled[:, i:i+1]).flatten()\n",
        "            y_val_original[:, i] = scaler.target_scalers[i].inverse_transform(\n",
        "                y_val[:, i:i+1]).flatten()\n",
        "        else:\n",
        "            val_preds[:, i] = val_preds_scaled[:, i]\n",
        "            y_val_original[:, i] = y_val[:, i]\n",
        "\n",
        "    target_maes = []\n",
        "    for i, target in enumerate(targets):\n",
        "        valid_indices = mask_val[:, i]\n",
        "        if valid_indices.sum() > 0:\n",
        "            target_mae = mean_absolute_error(\n",
        "                y_val_original[valid_indices, i],\n",
        "                val_preds[valid_indices, i]\n",
        "            )\n",
        "            target_maes.append(target_mae)\n",
        "            print(f\"  {target} MAE: {target_mae:.4f} (n={valid_indices.sum()})\")\n",
        "        else:\n",
        "            print(f\"  {target}: No valid samples\")\n",
        "\n",
        "    if target_maes:\n",
        "        val_mae = np.mean(target_maes)\n",
        "        fold_maes.append(val_mae)\n",
        "        print(f\"Fold {fold+1} Average MAE: {val_mae:.4f}\")\n",
        "\n",
        "    test_preds_scaled = trainer.predict(test_dataset).predictions\n",
        "    test_preds = np.zeros_like(test_preds_scaled)\n",
        "\n",
        "    for i, target in enumerate(targets):\n",
        "        if hasattr(scaler, 'target_scalers') and i in scaler.target_scalers:\n",
        "            test_preds[:, i] = scaler.target_scalers[i].inverse_transform(\n",
        "                test_preds_scaled[:, i:i+1]).flatten()\n",
        "        else:\n",
        "            test_preds[:, i] = test_preds_scaled[:, i]\n",
        "\n",
        "    test_preds_folds.append(test_preds)"
      ],
      "metadata": {
        "id": "eoR2XvcGidxQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afd57f8b-afde-4f6a-95c5-a3dd9d492244"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "--- Fold 1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ChemBERTaRegressor were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['regressor.bias', 'regressor.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1197' max='1197' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1197/1197 05:23, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>13.700400</td>\n",
              "      <td>10.627661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>8.132100</td>\n",
              "      <td>4.385361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>3.972300</td>\n",
              "      <td>3.781864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.392300</td>\n",
              "      <td>3.647170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>4.131000</td>\n",
              "      <td>3.596702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>3.703600</td>\n",
              "      <td>3.596913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>4.030100</td>\n",
              "      <td>3.491379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.717100</td>\n",
              "      <td>3.377570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>4.012300</td>\n",
              "      <td>3.332675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.720600</td>\n",
              "      <td>3.315939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>3.871500</td>\n",
              "      <td>3.212716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.496700</td>\n",
              "      <td>3.180485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>3.487500</td>\n",
              "      <td>3.184751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.046800</td>\n",
              "      <td>3.147587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>3.581800</td>\n",
              "      <td>3.113724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.265900</td>\n",
              "      <td>3.119288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>3.150600</td>\n",
              "      <td>3.081684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.280700</td>\n",
              "      <td>3.060277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>3.662800</td>\n",
              "      <td>3.058811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.258700</td>\n",
              "      <td>3.039773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>3.532000</td>\n",
              "      <td>3.036366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>3.046400</td>\n",
              "      <td>3.028079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>3.541600</td>\n",
              "      <td>3.023637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Tg MAE: 96.3588 (n=87)\n",
            "  FFV MAE: 0.0347 (n=1419)\n",
            "  Tc MAE: 0.1415 (n=145)\n",
            "  Density MAE: 0.6198 (n=123)\n",
            "  Rg MAE: 10.5548 (n=124)\n",
            "Fold 1 Average MAE: 21.5419\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fold 2 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ChemBERTaRegressor were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['regressor.bias', 'regressor.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1197' max='1197' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1197/1197 05:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>14.136600</td>\n",
              "      <td>10.941912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>6.927200</td>\n",
              "      <td>4.668564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>4.046900</td>\n",
              "      <td>4.143402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.134800</td>\n",
              "      <td>4.067165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>3.921000</td>\n",
              "      <td>3.980850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>3.876800</td>\n",
              "      <td>3.936046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>3.445200</td>\n",
              "      <td>3.932721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.720000</td>\n",
              "      <td>3.806639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>3.502900</td>\n",
              "      <td>3.772038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.351100</td>\n",
              "      <td>3.707113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>3.434200</td>\n",
              "      <td>3.675210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.551900</td>\n",
              "      <td>3.671831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>3.562600</td>\n",
              "      <td>3.667378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.220800</td>\n",
              "      <td>3.624856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>3.056700</td>\n",
              "      <td>3.599108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.474700</td>\n",
              "      <td>3.610184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>3.033300</td>\n",
              "      <td>3.549553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>2.996100</td>\n",
              "      <td>3.583036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>3.446600</td>\n",
              "      <td>3.562139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.232200</td>\n",
              "      <td>3.566722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>3.116500</td>\n",
              "      <td>3.557337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>3.463400</td>\n",
              "      <td>3.524815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>3.291700</td>\n",
              "      <td>3.514007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Tg MAE: 112.6584 (n=112)\n",
            "  FFV MAE: 0.0356 (n=1393)\n",
            "  Tc MAE: 0.1249 (n=144)\n",
            "  Density MAE: 0.6285 (n=117)\n",
            "  Rg MAE: 10.4588 (n=119)\n",
            "Fold 2 Average MAE: 24.7812\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fold 3 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ChemBERTaRegressor were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['regressor.bias', 'regressor.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1197' max='1197' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1197/1197 05:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>14.086600</td>\n",
              "      <td>10.600896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>6.982000</td>\n",
              "      <td>4.404428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>4.297100</td>\n",
              "      <td>3.961670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.839600</td>\n",
              "      <td>3.810129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>3.760900</td>\n",
              "      <td>3.771698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>4.217900</td>\n",
              "      <td>3.691284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>4.274000</td>\n",
              "      <td>3.660346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.735900</td>\n",
              "      <td>3.565757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>4.055400</td>\n",
              "      <td>3.547144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.489300</td>\n",
              "      <td>3.507576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>3.412600</td>\n",
              "      <td>3.451814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.912800</td>\n",
              "      <td>3.450933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>3.057500</td>\n",
              "      <td>3.442268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.405700</td>\n",
              "      <td>3.424306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>3.181400</td>\n",
              "      <td>3.432070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.017000</td>\n",
              "      <td>3.431076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>3.103900</td>\n",
              "      <td>3.418316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.224100</td>\n",
              "      <td>3.406659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>3.388900</td>\n",
              "      <td>3.359399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.213800</td>\n",
              "      <td>3.355304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>3.120000</td>\n",
              "      <td>3.353307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>3.113600</td>\n",
              "      <td>3.353586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>3.209000</td>\n",
              "      <td>3.352527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Tg MAE: 111.4069 (n=113)\n",
            "  FFV MAE: 0.0348 (n=1409)\n",
            "  Tc MAE: 0.1346 (n=138)\n",
            "  Density MAE: 0.6520 (n=113)\n",
            "  Rg MAE: 11.1525 (n=112)\n",
            "Fold 3 Average MAE: 24.6762\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fold 4 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ChemBERTaRegressor were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['regressor.bias', 'regressor.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1197' max='1197' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1197/1197 05:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>14.537200</td>\n",
              "      <td>10.583584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>7.123600</td>\n",
              "      <td>4.561779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>4.417900</td>\n",
              "      <td>4.010751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.884500</td>\n",
              "      <td>3.867895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>4.046500</td>\n",
              "      <td>3.791548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>3.148700</td>\n",
              "      <td>3.849463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>3.848800</td>\n",
              "      <td>3.694699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>4.031400</td>\n",
              "      <td>3.616822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>3.815900</td>\n",
              "      <td>3.607808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.689200</td>\n",
              "      <td>3.566598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>3.543200</td>\n",
              "      <td>3.635043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.141100</td>\n",
              "      <td>3.647414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>3.179200</td>\n",
              "      <td>3.506629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.616300</td>\n",
              "      <td>3.480617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>2.982600</td>\n",
              "      <td>3.488594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.368500</td>\n",
              "      <td>3.462655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>3.233300</td>\n",
              "      <td>3.442925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.414200</td>\n",
              "      <td>3.477921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>3.320300</td>\n",
              "      <td>3.470581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.214200</td>\n",
              "      <td>3.474658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>3.355300</td>\n",
              "      <td>3.448575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>3.305500</td>\n",
              "      <td>3.434940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>2.924100</td>\n",
              "      <td>3.447989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Tg MAE: 105.5811 (n=104)\n",
            "  FFV MAE: 0.0348 (n=1402)\n",
            "  Tc MAE: 0.1317 (n=153)\n",
            "  Density MAE: 0.6840 (n=130)\n",
            "  Rg MAE: 11.3570 (n=130)\n",
            "Fold 4 Average MAE: 23.5577\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fold 5 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ChemBERTaRegressor were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['regressor.bias', 'regressor.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1197' max='1197' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1197/1197 05:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>14.510200</td>\n",
              "      <td>10.606109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>7.250700</td>\n",
              "      <td>4.486927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>3.097800</td>\n",
              "      <td>4.061602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.400900</td>\n",
              "      <td>3.929353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>4.334800</td>\n",
              "      <td>3.865764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>4.019800</td>\n",
              "      <td>3.761167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>3.648000</td>\n",
              "      <td>3.750860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.726900</td>\n",
              "      <td>3.650390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>3.293000</td>\n",
              "      <td>3.647531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.356900</td>\n",
              "      <td>3.677191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>3.000200</td>\n",
              "      <td>3.572328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.704900</td>\n",
              "      <td>3.601170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>3.330000</td>\n",
              "      <td>3.512487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.457700</td>\n",
              "      <td>3.525623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>3.816800</td>\n",
              "      <td>3.451638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.551300</td>\n",
              "      <td>3.450627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>3.169600</td>\n",
              "      <td>3.403569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.382900</td>\n",
              "      <td>3.401871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>2.961400</td>\n",
              "      <td>3.437178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.226200</td>\n",
              "      <td>3.434375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>2.980300</td>\n",
              "      <td>3.409976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>3.049000</td>\n",
              "      <td>3.431747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>3.647300</td>\n",
              "      <td>3.404737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Tg MAE: 101.5340 (n=95)\n",
            "  FFV MAE: 0.0351 (n=1407)\n",
            "  Tc MAE: 0.1418 (n=157)\n",
            "  Density MAE: 0.7080 (n=130)\n",
            "  Rg MAE: 11.5285 (n=129)\n",
            "Fold 5 Average MAE: 22.7895\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_test_preds = np.mean(test_preds_folds, axis=0)\n",
        "print(f\"\\nAverage CV MAE: {np.mean(fold_maes):.4f}\")\n",
        "\n",
        "submission = pd.DataFrame(final_test_preds, columns=targets)\n",
        "submission.insert(0, 'id', test_df['id'])\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"submission.csv file has been created woohoo! abhinav, shaan, and sahil are the best.\")"
      ],
      "metadata": {
        "id": "NZ7cA-t5exoH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9def5ddf-852f-4765-e335-9b98dff8c80f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average CV MAE: 23.4693\n",
            "submission.csv file has been created woohoo! abhinav, shaan, and sahil are the best.\n"
          ]
        }
      ]
    }
  ]
}